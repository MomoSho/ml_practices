{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NAME:__ __FULLNAME__  \n",
    "__SECTION:__ __NUMBER__  \n",
    "__CS 5970: Machine Learning Practices__\n",
    "\n",
    "# Homework 13: Clustering\n",
    "\n",
    "## Assignment Overview\n",
    "Follow the TODOs and read through and understand any provided code.  \n",
    "For all plots, make sure all necessary axes and curves are clearly and \n",
    "accurately labeled. Include figure/plot titles appropriately as well.\n",
    "Post any questions to the Canvas Discussion.\n",
    "\n",
    "For this assignment you will be exploring clustering. Clustering is an unsupervised learning technique that can be utilized to discover interesting patterns or groupings amongst data.\n",
    "\n",
    "Select one of the two tasks below\n",
    "\n",
    "### [Task 1](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)\n",
    "Explore clustering for the Human Activity Recognition dataset. Recordings come from 30 subjects\n",
    "performing activities of daily living while carrying a waist-mounted smartphone with embedded\n",
    "inertial sensors.\n",
    "\n",
    "\n",
    "### Task 2\n",
    "Explore clustering for a few synthetic datasets.\n",
    "\n",
    "\n",
    "### Objectives\n",
    "* Clustering\n",
    "* Dimensionality Reduction\n",
    "\n",
    "### Notes\n",
    "* Do not save work within the ml_practices folder\n",
    "\n",
    "### General References\n",
    "* [Guide to Jupyter](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)\n",
    "* [Python Built-in Functions](https://docs.python.org/3/library/functions.html)\n",
    "* [Python Data Structures](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n",
    "* [Numpy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)\n",
    "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n",
    "* [DataCamp: Matplotlib](https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python?utm_source=adwords_ppc&utm_campaignid=1565261270&utm_adgroupid=67750485268&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=1t1&utm_creative=332661264365&utm_targetid=aud-299261629574:dsa-473406587955&utm_loc_interest_ms=&utm_loc_physical_ms=9026223&gclid=CjwKCAjw_uDsBRAMEiwAaFiHa8xhgCsO9wVcuZPGjAyVGTitb_-fxYtkBLkQ4E_GjSCZFVCqYCGkphoCjucQAvD_BwE)\n",
    "* [Pandas DataFrames](https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_reference_api_pandas.DataFrame.html&d=DwMD-g&c=qKdtBuuu6dQK9MsRUVJ2DPXW6oayO8fu4TfEHS8sGNk&r=9ngmsG8rSmDSS-O0b_V0gP-nN_33Vr52qbY3KXuDY5k&m=mcOOc8D0knaNNmmnTEo_F_WmT4j6_nUSL_yoPmGlLWQ&s=h7hQjqucR7tZyfZXxnoy3iitIr32YlrqiFyPATkW3lw&e=)\n",
    "* [Sci-kit Learn Linear Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "* [Sci-kit Learn Ensemble Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)\n",
    "* [Sci-kit Learn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "* [Sci-kit Learn Model Selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "* [Sci-kit Learn Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "* [Sci-kit Learn Preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import sys\n",
    "sys.path.insert(0, \"../hw09\")\n",
    "\n",
    "# THESE 4 IMPORTS ARE CUSTOM .py FILES AND CAN BE FOUND \n",
    "# ON THE SERVER AND GIT\n",
    "import visualize\n",
    "import metrics_plots\n",
    "from pipeline_components import DataSampleDropper, DataFrameSelector\n",
    "from pipeline_components import DataScaler, DataLabelEncoder\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import os, re, fnmatch\n",
    "import pathlib, itertools\n",
    "import time as timelib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as peffects\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, auc, f1_score\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "FIGWIDTH = 5\n",
    "FIGHEIGHT = 5\n",
    "FONTSIZE = 12\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (FIGWIDTH, FIGHEIGHT)\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display current working directory of this notebook. If you are using \n",
    "relative paths for your data, then it needs to be relative to the CWD.\n",
    "\"\"\"\n",
    "HOME_DIR = pathlib.Path.home()\n",
    "pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1 DATASET: UCI_HAR_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones\n",
    "\n",
    "Abstract: Human Activity Recognition database built from the recordings of 30 subjects\n",
    "performing activities of daily living (ADL) while carrying a waist-mounted smartphone \n",
    "with embedded inertial sensors.\n",
    "\n",
    "Number of Attributes: 561\n",
    "\n",
    "Source:\n",
    "Jorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and\n",
    "Xavier Parra(2)\n",
    "1 - Smartlab - Non-Linear Complex Systems Laboratory\n",
    "DITEN - Università degli Studi di Genova, Genoa (I-16145), Italy.\n",
    "2 - CETpD - Technical Research Centre for Dependency Care and Autonomous Living\n",
    "Universitat Politècnica de Catalunya (BarcelonaTech). Vilanova i la Geltrú (08800), \n",
    "Spain activityrecognition '@' smartlab.ws\n",
    "\n",
    "\n",
    "Data Set Information:\n",
    "The experiments have been carried out with a group of 30 subjects. Each person\n",
    "performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, \n",
    "STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. \n",
    "\n",
    "The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise \n",
    "filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap\n",
    "(128 readings/window).\n",
    "\n",
    "Check the README.txt file for further details about this dataset.\n",
    "\n",
    "Attribute Information:\n",
    "For each record in the dataset it is provided:\n",
    "- Triaxial acceleration from the accelerometer (total acceleration) and the \n",
    "  estimated body acceleration.\n",
    "- Triaxial Angular velocity from the gyroscope.\n",
    "- A 561-feature vector with time and frequency domain variables.\n",
    "- Its activity label.\n",
    "- An identifier of the subject who carried out the experiment.\n",
    "\n",
    "Citation:\n",
    "Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.\n",
    "\"\"\"\n",
    "# TODO: Set any data file paths appropriately\n",
    "data = pd.read_csv('UCI_HAR_Dataset/uci_har_Xy_train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Check for any NaNs\n",
    "\"\"\"\n",
    "data.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Class counts\n",
    "use pd.value_counts(data['activity_label']) to determine how many instances there \n",
    "are for each activity class\n",
    "\"\"\"\n",
    "cnt = # TODO\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Feature names for each column in the data\n",
    "\"\"\"\n",
    "features = pd.read_csv('UCI_HAR_Dataset/meta/features.txt', sep='\\s+', header=None)\n",
    "features.columns = ['num', 'feature_name']\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Activity Class Label names\n",
    "\"\"\"\n",
    "activity_labels = pd.read_csv('UCI_HAR_Dataset/meta/activity_labels.txt', sep='\\s+', header=None)\n",
    "activity_labels.columns = ['num', 'activity_name']\n",
    "nclasses, ncols = activity_labels.shape\n",
    "nclasses, ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display class names and corresponding number\n",
    "activity_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out just the class names\n",
    "activity_names = list(activity_labels['activity_name'].values)\n",
    "activity_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARTITION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Separate the data into X and y. Use the features variable to pull out the \n",
    "appropriate feature data. For y we are predicting the 'activity_label' \n",
    "column from the data.\n",
    "\n",
    "Hold out a subset of the data, using train_test_split, a test_size \n",
    "fraction of .2, and shuffle to False\n",
    "\"\"\"\n",
    "# Feature Names\n",
    "feature_names = features['feature_name'].values\n",
    "\n",
    "# TODO: Separate the data into X and y\n",
    "X = # TODO\n",
    "\n",
    "# Substract 1 from the label number for convenience, such that number matches\n",
    "# the list index. i.e. changing the label numbers from 1 to 6 to 0 to 5\n",
    "y = data['activity_label'].copy().values - 1\n",
    "\n",
    "# TODO: Split into train and validation\n",
    "\n",
    "\n",
    "\n",
    "nsamples_train = Xtrain.shape[0]\n",
    "\n",
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_scatter_plot(X, labels, feature_names, label_names, centers=None,\n",
    "                         leg_on=False, FIGSIZE=(15,10), elev=35, angle=310):\n",
    "    '''\n",
    "    Plot 2D or 3D scatter plots of selected sets of features\n",
    "    PARAMS:\n",
    "        X: full feature space as a dataframe\n",
    "        labels: labels for each example in X\n",
    "        feature_names: subset of features to plot from X\n",
    "        label_names: contains nclass elements, where each element is the name \n",
    "                     for each class (Note: only viable for classes not clusters)\n",
    "        centers: nclass-by-2 or nclass-by-3 matrix of group centers.\n",
    "        leg_on: flag whether to display the legend (Note: only set True when \n",
    "                plotting the actual class groupings. False when displaying clusters)\n",
    "        FIGSIZE: tuple of figure width and height\n",
    "        elev: 3D plot view elevation\n",
    "        angle: 3D plot view angle\n",
    "    '''\n",
    "    # Select a subset of features\n",
    "    data = X[feature_names].copy().values\n",
    "\n",
    "    # Create the figure\n",
    "    fig = plt.figure(figsize=FIGSIZE)\n",
    "    \n",
    "    # 2D Plots\n",
    "    if data.shape[1] == 2:\n",
    "        ax0 = fig.add_subplot(111)\n",
    "        # Plot the points by class or cluster\n",
    "        for i, name in enumerate(label_names):\n",
    "            inds = labels == i\n",
    "            ax0.scatter(data[inds,0], data[inds,1], label=name)\n",
    "        if leg_on: ax0.legend()\n",
    "        \n",
    "    # 3D Plots\n",
    "    elif data.shape[1] > 2:\n",
    "        ax0 = fig.add_subplot(111, projection='3d')\n",
    "        # Plot the points by class or cluster\n",
    "        for i, name in enumerate(label_names):\n",
    "            inds = labels == i\n",
    "            ax0.scatter(data[inds,0], data[inds,1], data[inds,2], label=name)\n",
    "        ax0.view_init(elev, angle)\n",
    "        if leg_on: ax0.legend()\n",
    "    \n",
    "    if centers is not None:\n",
    "        # Plot the group centers\n",
    "        mn = np.min(labels)\n",
    "        mx = np.max(labels)\n",
    "        if data.shape[1] == 2:\n",
    "            ax0.scatter(centers[:,0], centers[:,1], c=np.arange(mn, mx+1), \n",
    "                        marker='D', cmap=plt.cm.rainbow)\n",
    "        elif data.shape[1] > 2:\n",
    "            ax0.scatter(centers[:,0], centers[:,1], centers[:,2], \n",
    "                       c=np.arange(mn, mx+1), marker='D', cmap=plt.cm.rainbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_centers(X, y, feature_names, classes):\n",
    "    '''\n",
    "    Compute group centers within the selected sub-feature space\n",
    "    PARAMS:\n",
    "        X: full feature space\n",
    "        y: labels for each example in X\n",
    "        classes: contains nclass elements, where each element is the index for each class\n",
    "    '''\n",
    "    data = X[feature_names].copy().values\n",
    "\n",
    "    nclasses = len(classes)\n",
    "    nfeats = len(feature_names)\n",
    "    centers = np.empty((nclasses, nfeats))\n",
    "    \n",
    "    for c in classes:\n",
    "        centers[c, :] = np.mean(data[y == c, :], axis=0)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Use the following two cells.\n",
    "\n",
    "Observe and analyze 2 feature subspaces of 2 or 3 features. To do this select sets\n",
    "of 2 or 3 features. For example, consider the feature subspace defined by the features\n",
    "'tBodyAcc-entropy()-X', 'tBodyAcc-entropy()-Y' and 'tBodyAcc-entropy()-Z'.\n",
    "\n",
    "First plot the actual classifications in this subspace using:\n",
    "    group_scatter_plot(Xtrain, ytrain, selected_feats, activity_names, leg_on=True, angle=300)\n",
    "\n",
    "Second, construct a KMeans model for unsupervised learning of various clusterings of\n",
    "the data in the selected feature subspaces. Use predict on the KMeans model to determine\n",
    "the set of 6 clusters. Use group_scatter_plot(leg_on=False) with the predicted clusters as the \n",
    "labels, and not the real classifications. Display the model's interia (i.e. the sum of squared\n",
    "distances of samples to their closest cluster center)\n",
    "\"\"\"\n",
    "angle = 300\n",
    "\n",
    "feats = # TODO: list of subset of selected features\n",
    "# TODO: Plot Actual classifications. use group_scatter_plot with leg_on=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Determine clusters. Create KMeans model and predict the clusters\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Plot determined clusters. use group_scatter_plot with leg_on=False\n",
    "\n",
    "\n",
    "\n",
    "# Sum of squared distances of samples to their closest cluster center\n",
    "model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Observe the class groupings in the second selected feature subspace:\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsoMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Reduce the full feature space (i.e. all 561 features) down to \n",
    "2 features (i.e n_components) using Isomap. Also, make sure to \n",
    "determine a goodchoice for the number of neighbors.\n",
    "\n",
    "Display the classes in the new feature space.\n",
    "\n",
    "Then construct a KMeans model to locate a set of 6 clusters\n",
    "in this new feature subspace. Display the determined clusters in \n",
    "this new feature subspace.\n",
    "\"\"\"\n",
    "# TODO: Create the Isomap object and transform the training data\n",
    "isomap2 = # TODO: create Isomap object\n",
    "Xmap2 = # TODO: transform the training data\n",
    "\n",
    "# TODO: Plot actual classifications in the new feature space\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax0 = fig.add_subplot(111)\n",
    "for i, name in enumerate(activity_names):\n",
    "    # Mask of examples belonging to the current class \n",
    "    inds = ytrain == i\n",
    "    # TODO: use scatter to plot the selected examples in the isomap\n",
    "    # subspace. set the label to the class name\n",
    "    # see the API pages for matplotlib scatter\n",
    "    \n",
    "ax0.set_title('Actual Classifications')\n",
    "ax0.legend()\n",
    "\n",
    "\n",
    "# TODO: Construct a KMeans Model. fit it to the Isomap features\n",
    "iso2_model = # TODO: create and fit the model\n",
    "# TODO: determine the cluster groupings using predict\n",
    "pred = # TODO\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Plot determined predicted clusters\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax0 = fig.add_subplot(111)\n",
    "# TODO: use scatter to plot all the examples in the isomap subspace.\n",
    "# do NOT set the label, instead set the parameter c to the predicted clusters\n",
    "# see the API pages for matplotlib scatter\n",
    "\n",
    "ax0.set_title('Determined clusters')\n",
    "\n",
    "# Sum of squared distances of samples to their closest cluster center\n",
    "iso2_model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Reduce the full feature space (i.e. all 561 features) down to \n",
    "3 features using Isomap. Also, make sure to determine a good \n",
    "choice for the number of neighbors.\n",
    "\n",
    "Display the classes in the new feature space.\n",
    "\n",
    "Then construct a KMeans model to locate a set of 6 clusters\n",
    "in this new feature space. Display the determined clusters in \n",
    "this new feature space.\n",
    "\"\"\"\n",
    "# TODO: Create the Isomap object and transform the training data\n",
    "isomap3 = # TODO\n",
    "Xmap3 = # TODO\n",
    "\n",
    "# TODO: Plot actual classifications in the new feature space\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax0 = fig.add_subplot(111, projection='3d')\n",
    "for i, name in enumerate(activity_names):\n",
    "    # Mask of examples belonging to the current class \n",
    "    inds = ytrain == i\n",
    "    # TODO: use scatter to plot the selected examples in the isomap\n",
    "    # subspace. set the label to the class name\n",
    "    \n",
    "    \n",
    "ax0.set_title('Actual Classifications')\n",
    "ax0.legend()\n",
    "\n",
    "\n",
    "# TODO: Construct a KMeans Model\n",
    "iso3_model = # TODO\n",
    "# TODO: determine the cluster groupings\n",
    "pred = # TODO\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Plot determined clusters\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax0 = fig.add_subplot(111, projection='3d')\n",
    "# TODO: use scatter to plot all the examples in the isomap subspace.\n",
    "# do NOT set the label, instead set the parameter c to the predicted clusters\n",
    "\n",
    "ax0.set_title('Determined clusters')\n",
    "\n",
    "iso3_model.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Reduce the full feature space (i.e. all 561 features) down to \n",
    "2 features using PCA. Also, set whiten to True.\n",
    "\n",
    "Display the classes in the new feature space.\n",
    "\n",
    "Then construct a KMeans model to locate a set of 6 clusters\n",
    "in this new feature space. Display the determined clusters in \n",
    "this new feature space.\n",
    "\"\"\"\n",
    "# TODO: Create the PCA object and transform the training data\n",
    "pca2 = # TODO\n",
    "Xpca2 = # TODO\n",
    "\n",
    "# TODO: Plot actual classifications in the new feature space\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax0 = fig.add_subplot(111)\n",
    "for i, name in enumerate(activity_names):\n",
    "    # Mask of examples belonging to the current class \n",
    "    inds = ytrain == i\n",
    "    # TODO: use scatter to plot the selected examples in the PCA\n",
    "    # subspace. set the label to the class name\n",
    "    # see the API pages for matplotlib scatter\n",
    "\n",
    "ax0.set_title('Actual Classifications')\n",
    "ax0.legend()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Construct a KMeans Model. fit the model to the PCA features\n",
    "pca2_model = # TODO\n",
    "# TODO: determine the cluster groupings\n",
    "pred = # TODO\n",
    "\n",
    "# TODO: Plot determined clusters\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax0 = fig.add_subplot(111)\n",
    "# TODO: use scatter to plot all the examples in the isomap subspace.\n",
    "# do not set the label, instead set the parameter c to the predicted clusters\n",
    "# see the API pages for matplotlib scatter\n",
    "\n",
    "ax0.set_title('Determined clusters')\n",
    "\n",
    "pca2_model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Reduce the full feature space (i.e. all 561 features) down to \n",
    "3 features using PCA. Also, set whiten to True.\n",
    "\n",
    "Display the classes in the new feature space.\n",
    "\n",
    "Then construct a KMeans model to locate a set of 6 clusters\n",
    "in this new feature space. Display the determined clusters in \n",
    "this new feature space.\n",
    "\"\"\"\n",
    "# TODO: Create the PCA object and transform the training data\n",
    "pca3 = # TODO\n",
    "Xpca3 = # TODO\n",
    "\n",
    "# TODO: Plot actual classifications in the new feature space\n",
    "elev = 25\n",
    "angle = 300\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax0 = fig.add_subplot(111, projection='3d')\n",
    "for i, name in enumerate(activity_names):\n",
    "    # Mask of examples belonging to the current class \n",
    "    inds = ytrain == i\n",
    "    # TODO: use scatter to plot the selected examples in the PCA\n",
    "    # subspace. set the label to the class name\n",
    "    # see the API pages for matplotlib scatter\n",
    "\n",
    "ax0.view_init(elev, angle)\n",
    "ax0.set_title('Actual Classifications')\n",
    "ax0.legend()\n",
    "\n",
    "\n",
    "# TODO: Construct a KMeans Model. fit the model on the PCA features\n",
    "pca3_model = # TODO\n",
    "# TODO: determine the cluster groupings\n",
    "pred = # TODO\n",
    "\n",
    "# TODO: Plot determined clusters\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax0 = fig.add_subplot(111, projection='3d')\n",
    "# TODO: use scatter to plot all the examples in the isomap subspace.\n",
    "# do not set the label, instead set the parameter c to the predicted clusters\n",
    "# see the API pages for matplotlib scatter\n",
    "\n",
    "ax0.view_init(elev, angle)\n",
    "ax0.set_title('Determined clusters')\n",
    "\n",
    "pca3_model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2 DATASETS: SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Load the dataset\n",
    "\"\"\"\n",
    "D31 = pd.read_csv('synthetic/D31.txt', sep='\\s+', header=None)\n",
    "D31.columns = ['x', 'y', 'cluster']\n",
    "D31['cluster'] = D31['cluster'] - 1\n",
    "D31.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few examples\n",
    "D31.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display class counts using pd.value_counts() on the clusters column\n",
    "\"\"\"\n",
    "d31_cnt = # TODO\n",
    "d31_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the actual classifications and the predicted clusters\n",
    "\"\"\"\n",
    "# TODO: Plot true classifications. use group_scatter_plot. \n",
    "# the feature names are ['x', 'y']. the label names are d31_cnt.index\n",
    "\n",
    "\n",
    "# TODO: Determine a set of clusters using KMeans\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Plot the determined clusters. use group_scatter_plot. \n",
    "\n",
    "\n",
    "model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGGREGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Load the dataset\n",
    "\"\"\"\n",
    "Aggregation = pd.read_csv('synthetic/Aggregation.txt', sep='\\s+', header=None)\n",
    "Aggregation.columns = ['x', 'y', 'cluster']\n",
    "Aggregation['cluster'] = Aggregation['cluster'] - 1\n",
    "Aggregation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few examples\n",
    "Aggregation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display class counts\n",
    "\"\"\"\n",
    "agg_cnt = # TODO\n",
    "agg_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the actual and predicted clusters\n",
    "\"\"\"\n",
    "# TODO: Plot true classifications. use group_scatter_plot. \n",
    "# the feature names are ['x', 'y']. the label names are agg_cnt.index\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Determine clusters using KMeans\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Plot the determined clusters. use group_scatter_plot. \n",
    "\n",
    "\n",
    "model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Load the dataset\n",
    "\"\"\"\n",
    "R15 = pd.read_csv('synthetic/R15.txt', sep='\\s+', header=None)\n",
    "R15.columns = ['x', 'y', 'cluster']\n",
    "R15['cluster'] = R15['cluster'] - 1\n",
    "R15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few examples\n",
    "R15.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display class counts\n",
    "\"\"\"\n",
    "r15_cnt = # TODO\n",
    "r15_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display the actual and predicted clusters\n",
    "\"\"\"\n",
    "# TODO: Plot true classifications. use group_scatter_plot. \n",
    "# the feature names are ['x', 'y']. the label names are r15_cnt.index\n",
    "\n",
    "\n",
    "# TODO: Determine clusters using KMeans\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Plot the determined clusters. use group_scatter_plot. \n",
    "\n",
    "\n",
    "model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCUSSION\n",
    "For which ever task you selected, answer the following question:\n",
    "\n",
    "In several paragraphs describe the original clusters and compare them to the clusters learned by the KMeans model. What are the limitations or issues with the learned clusters? Please be clear and concise in your response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
