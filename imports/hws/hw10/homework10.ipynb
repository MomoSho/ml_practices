{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NAME:__ __FULLNAME__  \n",
    "__SECTION:__ __NUMBER__  \n",
    "__CS 5970: Machine Learning Practices__\n",
    "\n",
    "# Homework 10: FORESTS AND BOOSTING\n",
    "\n",
    "## Assignment Overview\n",
    "Follow the TODOs and read through and understand any provided code.  \n",
    "For all plots, make sure all necessary axes and curves are clearly and \n",
    "accurately labeled. Include figure/plot titles appropriately as well.\n",
    "If you have any questions, please post them to the Canvas Discussion.\n",
    "\n",
    "### Task\n",
    "For this assignment you will be exploring Random Forests and Boosting.\n",
    "\n",
    "### [Data set](https://www.kaggle.com/noaa/hurricane-database)\n",
    "The dataset is based on cyclone weather data from NOAA.  \n",
    "You can obtain the data from the server and git under datasets/cyclones.\n",
    "\n",
    "We will be predicting whether a cyclone status is a tropical depression (TD) or not.  \n",
    "Status can be the following types:  \n",
    "* TD – tropical depression  \n",
    "* TS – tropical storm   \n",
    "* HU – hurricane intensity  \n",
    "* EX – Extratropical cyclone  \n",
    "* SD – subtropical depression intensity  \n",
    "* SS – subtropical storm intensity  \n",
    "* LO – low, neither a tropical, subtropical, nor extratropical cyclone  \n",
    "* WV – Tropical Wave  \n",
    "* DB – Disturbance  \n",
    "\n",
    "\n",
    "### Objectives\n",
    "* DecisionTreeClassifiers\n",
    "* RandomForests\n",
    "* Boosting\n",
    "\n",
    "### Notes\n",
    "* Do not save work within the ml_practices folder\n",
    "\n",
    "### General References\n",
    "* [Guide to Jupyter](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)\n",
    "* [Python Built-in Functions](https://docs.python.org/3/library/functions.html)\n",
    "* [Python Data Structures](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n",
    "* [Numpy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)\n",
    "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n",
    "* [DataCamp: Matplotlib](https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python?utm_source=adwords_ppc&utm_campaignid=1565261270&utm_adgroupid=67750485268&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=1t1&utm_creative=332661264365&utm_targetid=aud-299261629574:dsa-473406587955&utm_loc_interest_ms=&utm_loc_physical_ms=9026223&gclid=CjwKCAjw_uDsBRAMEiwAaFiHa8xhgCsO9wVcuZPGjAyVGTitb_-fxYtkBLkQ4E_GjSCZFVCqYCGkphoCjucQAvD_BwE)\n",
    "* [Pandas DataFrames](https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_reference_api_pandas.DataFrame.html&d=DwMD-g&c=qKdtBuuu6dQK9MsRUVJ2DPXW6oayO8fu4TfEHS8sGNk&r=9ngmsG8rSmDSS-O0b_V0gP-nN_33Vr52qbY3KXuDY5k&m=mcOOc8D0knaNNmmnTEo_F_WmT4j6_nUSL_yoPmGlLWQ&s=h7hQjqucR7tZyfZXxnoy3iitIr32YlrqiFyPATkW3lw&e=)\n",
    "* [Sci-kit Learn Trees](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree)\n",
    "* [Sci-kit Learn Ensemble Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)\n",
    "* [Sci-kit Learn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "* [Sci-kit Learn Model Selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "* [Sci-kit Learn Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "* [Sci-kit Learn Preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# THESE 3 IMPORTS ARE CUSTOM .py FILES AND CAN BE FOUND \n",
    "# ON THE SERVER AND GIT\n",
    "import visualize\n",
    "import metrics_plots\n",
    "from pipeline_components import DataSampleDropper, DataFrameSelector\n",
    "from pipeline_components import DataScaler, DataLabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import os, re, fnmatch\n",
    "import pathlib, itertools, time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as peffects\n",
    "import time as timelib\n",
    "\n",
    "from math import ceil, floor\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, mean_squared_error, roc_curve, auc\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "FIGW = 5\n",
    "FIGH = 5\n",
    "FONTSIZE = 12\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (FIGW, FIGH)\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display current working directory of this notebook. If you are using \n",
    "relative paths for your data, then it needs to be relative to the CWD.\n",
    "\"\"\"\n",
    "HOME_DIR = pathlib.Path.home()\n",
    "pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set appropriately\n",
    "filename = 'cyclones/atlantic.csv'\n",
    "\n",
    "cyclones_full = pd.read_csv(filename)\n",
    "nRows, nCols = cyclones_full.shape\n",
    "print(f'{nRows} rows and {nCols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "not tropical depression (negative case = 0)\n",
    "is tropical depression (positive case = 1)\n",
    "\"\"\"\n",
    "targetnames = ['notTropDepress', 'isTropDrepress']\n",
    "\n",
    "# Determine the positve count\n",
    "isTD = cyclones_full['Status'].str.contains('TD')\n",
    "cyclones_full['isTD'] = isTD\n",
    "npos = isTD.sum() \n",
    "nneg = nRows - npos \n",
    "\n",
    "# Compute the postive fraction\n",
    "pos_fraction = npos / nRows\n",
    "neg_fraction = 1 - pos_fraction\n",
    "pos_fraction, neg_fraction\n",
    "\n",
    "(npos, pos_fraction), (nneg, neg_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Make some adjustments to the data.\n",
    "\n",
    "For wind speed, NaNs are current represented by -999.\n",
    "We will replace these with NaN.\n",
    "\n",
    "For Latitude and Longitude, these are strings such as \n",
    "28.0W. We will replace these with numerical values where\n",
    "positive directions are N and E, and negative directions \n",
    "are S and W.\n",
    "\"\"\"\n",
    "# Convert -999 values to NaNs. These are missing values\n",
    "NaNvalue = -999\n",
    "cyclones_nans = cyclones_full.replace(NaNvalue, np.nan).copy()\n",
    "\n",
    "# Set the datatype of the categorical attributes\n",
    "cate_attribs = ['Event', 'Status']\n",
    "cyclones_nans[cate_attribs] = cyclones_full[cate_attribs].astype('category')\n",
    "\n",
    "# Set the datatype of the Data attribute to datetime64[ns]\n",
    "cyclones_nans['Date'] = cyclones_nans['Date'].astype('datetime64[ns]')\n",
    "\n",
    "# Convert Latitude and Longitude into numerical values\n",
    "def to_numerical(coord):\n",
    "    direction = re.findall(r'[NSWE]' , coord)[0]\n",
    "    num = re.match('[\\d]{1,3}.[\\d]{0,1}' , coord)[0]\n",
    "    \n",
    "    # North and East are positive directions\n",
    "    if direction in ['N', 'E']:\n",
    "        return np.float(num)\n",
    "    return -1. * np.float(num)\n",
    "\n",
    "cyclones_nans['Latitude'] = cyclones_nans['Latitude'].apply(to_numerical)\n",
    "cyclones_nans['Longitude'] = cyclones_nans['Longitude'].apply(to_numerical)\n",
    "cyclones_nans[['Latitude', 'Longitude']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the quantitiy of NaNs for each feature\n",
    "\"\"\"\n",
    "cyclones_nans.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display summary statistics for each feature of the dataframe\n",
    "\"\"\"\n",
    "cyclones_nans.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclones_nans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Construct preprocessing pipeline\n",
    "\"\"\"\n",
    "dropped_features = ['ID', 'Name', 'Date', 'Time', 'Status', 'Event']\n",
    "#selected_features = cyclones_nans.columns.drop(dropped_features)\n",
    "selected_features = ['Latitude', 'Longitude', 'Low Wind SW', 'Moderate Wind NE', \n",
    "                     'Moderate Wind SE', 'High Wind NW', 'isTD']\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('FeatureSelector', DataFrameSelector(selected_features)),\n",
    "    ('RowDropper', DataSampleDropper())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Pre-process the data using the defined pipeline\n",
    "\"\"\"\n",
    "processed_data = pipe.fit_transform(cyclones_nans)\n",
    "nsamples, ncols = processed_data.shape\n",
    "nsamples, ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Verify all NaNs removed\n",
    "\"\"\"\n",
    "processed_data.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the distributions of the data\n",
    "use visualize.featureplots\n",
    "to generate trace plots, histograms, boxplots, and probability plots for\n",
    "each feature.\n",
    "\n",
    "A probability plot is utilized to evaulate the normality of a distribution.\n",
    "The data are plot against a theoritical distribution, such that if the data \n",
    "are normal, they'll follow the diagonal line. See the reference above for \n",
    "more information.\n",
    "\"\"\"\n",
    "cdata = processed_data.astype('float64').copy()\n",
    "visualize.featureplots(cdata.values, cdata.columns)\n",
    "# You can right click to enable scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the Pearson correlation between all pairs of the features\n",
    "use visualize.scatter_corrplots\n",
    "\"\"\"\n",
    "visualize.scatter_corrplots(cdata.values, cdata.columns, corrfmt=\"%.1f\", FIGW=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Extract the positive and negative cases\n",
    "\"\"\"\n",
    "# Get the positions of the positive and negative labeled examples\n",
    "pos_inds = processed_data['isTD'] == 1\n",
    "neg_inds = processed_data['isTD'] == 0\n",
    "\n",
    "# Get the actual corresponding examples\n",
    "pos = processed_data[pos_inds]\n",
    "neg = processed_data[neg_inds]\n",
    "\n",
    "# Positive Fraction\n",
    "npos = pos_inds.sum()\n",
    "nneg = nsamples - npos\n",
    "pos_frac = npos / nsamples\n",
    "neg_frac = 1 - pos_frac\n",
    "(npos, pos_frac), (nneg, neg_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Functions for exporting trees to .dot and .pngs\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "def image_combine(ntrees, big_name='big_tree.png', fname_fmt='tree_%02d.png'):\n",
    "    '''\n",
    "    Function for combining some of the trees in the forest into on image\n",
    "    Amalgamate the pngs of the trees into one big image\n",
    "    PARAMS:\n",
    "        ntrees: number of trees from the ensemble to export\n",
    "        big_name: file name for the png containing all ntrees\n",
    "        fname_fmt: file name format string used to read the exported files\n",
    "    '''\n",
    "    # Read the pngs\n",
    "    imgs = [Image.open(fname_fmt % x) for x in range(ntrees)]\n",
    "\n",
    "    # Determine the individual and total sizes\n",
    "    widths, heights = zip(*(i.size for i in imgs))\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    # Create the combined image\n",
    "    big_img = Image.new('RGB', (total_width, max_height))\n",
    "    x_offset = 0\n",
    "    for im in imgs:\n",
    "        big_img.paste(im, (x_offset, 0))\n",
    "        x_offset += im.size[0]\n",
    "    big_img.save(big_name) \n",
    "    print(\"Created %s\" % big_name)\n",
    "    return big_img\n",
    "\n",
    "def export_trees(forest, ntrees=3, fname_fmt='tree_%02d'):\n",
    "    '''\n",
    "    Write trees into inidividual files from the forest\n",
    "    PARAMS:\n",
    "        forest: ensemble of trees classifier\n",
    "        ntrees: number of trees from the ensemble to export\n",
    "        fname_fmt: file name format string used to name the exported files\n",
    "    '''\n",
    "    for t in range(ntrees):\n",
    "        estimator = forest.estimators_[t]\n",
    "        basename = fname_fmt % t\n",
    "        fname = basename + '.dot'\n",
    "        pngname = basename + '.png'\n",
    "        export_graphviz(estimator, out_file=fname, rounded=True, filled=True)\n",
    "        # Command line instruction to execute dot and create the image\n",
    "        !dot -Tpng {fname} > {pngname}\n",
    "        print(\"Created %s and %s\" % (fname, pngname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Split the data into X (i.e. the inputs) and y (i.e. the outputs).\n",
    "Recall we are predicting isTD.\n",
    "\n",
    "Hold out a subset of the data, before training and cross validation\n",
    "using train_test_split, with stratification, and a test_size \n",
    "fraction of .2. See the sklearn API for more details\n",
    "\n",
    "For this exploratory section, the held out set of data is a validation set.\n",
    "\"\"\"\n",
    "# TODO: Separate X and y. We are predicting isTD\n",
    "\n",
    "\n",
    "# TODO: Hold out 20% of the data for validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Create and train DecisionTree for comparision with the ensemble methods \n",
    "\"\"\"\n",
    "tree_clf = DecisionTreeClassifier(max_depth=200, max_leaf_nodes=10)\n",
    "tree_clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Compute the predictions, prediction probabilities, and the accuracy scores\n",
    "for the trianing and validation sets\n",
    "\"\"\"\n",
    "# Compute the model's predictions\n",
    "dt_preds = tree_clf.predict(Xtrain)\n",
    "dt_preds_val = tree_clf.predict(Xval)\n",
    "\n",
    "# Compute the prediction probabilities\n",
    "dt_proba = tree_clf.predict_proba(Xtrain)\n",
    "dt_proba_val = tree_clf.predict_proba(Xval)\n",
    "\n",
    "# Compute the model's mean accuracy\n",
    "dt_score = tree_clf.score(Xtrain, ytrain) \n",
    "dt_score_val = tree_clf.score(Xval, yval)\n",
    "\n",
    "# Confusion Matrix\n",
    "dt_cmtx = confusion_matrix(ytrain, dt_preds)\n",
    "dt_cmtx_val = confusion_matrix(yval, dt_preds_val)\n",
    "metrics_plots.confusion_mtx_colormap(dt_cmtx, targetnames, targetnames)\n",
    "metrics_plots.confusion_mtx_colormap(dt_cmtx_val, targetnames, targetnames)\n",
    "\n",
    "# KS, ROC, and PRC Curves\n",
    "dt_roc_prc_results = metrics_plots.ks_roc_prc_plot(ytrain, dt_proba[:,1])\n",
    "dt_roc_prc_results_val = metrics_plots.ks_roc_prc_plot(yval, dt_proba_val[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Export the tree as a .dot file and create the png\n",
    "\"\"\"\n",
    "fname = 'tree.dot'\n",
    "pngname = 'tree.png'\n",
    "export_graphviz(tree_clf, out_file=fname, rounded=True, filled=True)\n",
    "!dot -Tpng {fname} > {pngname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`![Best Model](tree.png)`\n",
    "![Best Model](tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Create and train RandomForests \n",
    "Explore various configurations of the hyper-parameters. \n",
    "Train the models on the training set and evaluate them for the training and\n",
    "validation sets.\n",
    "Take a look at the API and the book for the meaning and impact of different \n",
    "hyper-parameters\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Export some trees from your favorite model as a .dot file\n",
    "We can use the estimators_ attribute of the forest to get a list of the trees\n",
    "\n",
    "Amalgamate the pngs of the trees into one big image\n",
    "\"\"\"\n",
    "ntrees = 2\n",
    "export_trees(forest_clf, ntrees, fname_fmt='e_rf_model_%02d')\n",
    "big_img = image_combine(ntrees, big_name='e_rf_model.png', \n",
    "                        fname_fmt='e_rf_model_%02d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Forest](e_rf_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING AND VALIDATION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Compute the predictions, prediction probabilities, and the accuracy scores\n",
    "for the training and validation sets for the learned instance of the model\n",
    "\"\"\"\n",
    "# TODO: Compute the model's predictions. use model.predict()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Compute the prediction probabilities. use model.predict_proba()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Compute the model's mean accuracy. use model.score()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the confusion matrix, KS plot, ROC curve, and PR curve for the training \n",
    "and validation sets using metrics_plots.ks_roc_prc_plot\n",
    "\n",
    "The red dashed line in the ROC and PR plots are indicative of the expected \n",
    "performance for a random classifier, which would predict postives at the \n",
    "rate of occurance within the data set\n",
    "\"\"\"\n",
    "# TODO: Confusion Matrix\n",
    "\n",
    "\n",
    "\n",
    "# TODO: KS, ROC, and PRC Curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Create and train a Boosting model \n",
    "Explore various boosting models to improve your validation performance\n",
    "Train the models on the training set and evaluate them for the training and\n",
    "validation sets. Try boosting the benmark tree_clf\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING AND VALIDATION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Compute the predictions, prediction probabilities, and the accuracy scores\n",
    "for the trianing and validation sets\n",
    "\"\"\"\n",
    "# TODO: Compute the model's predictions\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Compute the prediction probabilities \n",
    "\n",
    "\n",
    "\n",
    "# TODO: Compute the model's scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the confusion matrix, KS plot, ROC curve, and PR curve for the \n",
    "training and validation sets using metrics_plots.ks_roc_prc_plot\n",
    "\"\"\" \n",
    "# TODO: Confusion Matrix\n",
    "\n",
    "\n",
    "\n",
    "# TODO: KS, ROC, and PRC Curves\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the feature imporantances\n",
    "see the API for RandomForests and boosted tree\n",
    "you can create a DataFrame to help with the display\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCUSSION\n",
    "1. In 2 to 4 paragraphs, discuss and interpret the report of your results for the RandomForestClassifier. Describe their meaning in terms of the context of predicting tropical depressions and the potential impact of various features. Talk about how you selected the hyper parameters. Describe how performance changes over the hyper-parameter space. \n",
    "\n",
    "2. Describe the impact of boosting in 1 to 2 paragraphs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
