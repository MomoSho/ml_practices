{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NAME:__ __FULLNAME__  \n",
    "__SECTION:__ __NUMBER__  \n",
    "__CS 5970: Machine Learning Practices__\n",
    "\n",
    "# Homework 9: Decision\n",
    "\n",
    "## Assignment Overview\n",
    "Follow the TODOs and read through and understand any provided code. \n",
    "Post any questions you might have to the Canvas discussion. \n",
    "For all plots, make sure all necessary axes and curves are clearly and \n",
    "accurately labeled. Include figure/plot titles appropriately as well.\n",
    "\n",
    "\n",
    "### Task\n",
    "For this assignment you will be exploring Decision Tree Classifiers.\n",
    "\n",
    "\n",
    "### [Data set](https://canvas.ou.edu/courses/163924/files/folder/Homework%20Solutions)\n",
    "\n",
    "The data file can be found on Canvas under Files/Homework Solutions, and on git and the server under datasets/fraud_detection/health_provider_fraud.csv.  \n",
    "\n",
    "These data were re-configured from a dataset collected for the purpose of detecting Health care Provider Fraud. Total Medicare spending increases exponentially due to frauds in Medicare claims. Healthcare fraud involves health care providers, physicians, patients, and beneficiaries acting intandum to construct fraudulent claims.\n",
    "\n",
    "The goal is to \"predict potentially fraudulent providers\" from summary statistics of their filed healthcare claims. \n",
    "\n",
    "__Features__  \n",
    "The features are aggregate statistics computed as either the mean or the sum.\n",
    "For the following features, the column is indicative of the average value for the provider's claims:  \n",
    "* InscClaimAmtReimbursed  \n",
    "* DeductibleAmtPaid\n",
    "* NoOfMonths_PartACov\n",
    "* NoOfMonths_PartBCov\n",
    "* IPAnnualReimbursementAmt\n",
    "* IPAnnualDeductibleAmt\n",
    "* OPAnnualReimbursementAmt\n",
    "* OPAnnualDeductibleAmt\n",
    "* NumPhysiciansSeen\n",
    "* NumProcedures\n",
    "* NumDiagnosisClaims\n",
    "* Age\n",
    " \n",
    "For the following features, the column is indicative of the total number among the provider's claims:  \n",
    "* ChronicCond_Alzheimer  \n",
    "* ChronicCond_Heartfailure  \n",
    "* ChronicCond_KidneyDisease  \n",
    "* ChronicCond_Cancer  \n",
    "* ChronicCond_ObstrPulmonary  \n",
    "* ChronicCond_Depression  \n",
    "* ChronicCond_Diabetes  \n",
    "* ChronicCond_IschemicHeart  \n",
    "* ChronicCond_Osteoporasis  \n",
    "* ChronicCond_rheumatoidarthritis  \n",
    "* ChronicCond_stroke  \n",
    "* RenalDiseaseIndicator  \n",
    "\n",
    "These data were amalagmated from the [HEALTHCARE PROVIDER FRAUD DETECTION ANALYSIS](https://www.kaggle.com/rohitrox/healthcare-provider-fraud-detection-analysis) data set on Kaggle.\n",
    "\n",
    "\n",
    "### Objectives\n",
    "* Introduction to Decision Trees\n",
    "\n",
    "\n",
    "### Notes\n",
    "* Do not save work within the ml_practices folder\n",
    "\n",
    "\n",
    "### General References\n",
    "* [Guide to Jupyter](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)\n",
    "* [Python Built-in Functions](https://docs.python.org/3/library/functions.html)\n",
    "* [Python Data Structures](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n",
    "* [Numpy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)\n",
    "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n",
    "* [DataCamp: Matplotlib](https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python?utm_source=adwords_ppc&utm_campaignid=1565261270&utm_adgroupid=67750485268&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=1t1&utm_creative=332661264365&utm_targetid=aud-299261629574:dsa-473406587955&utm_loc_interest_ms=&utm_loc_physical_ms=9026223&gclid=CjwKCAjw_uDsBRAMEiwAaFiHa8xhgCsO9wVcuZPGjAyVGTitb_-fxYtkBLkQ4E_GjSCZFVCqYCGkphoCjucQAvD_BwE)\n",
    "* [Pandas DataFrames](https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_reference_api_pandas.DataFrame.html&d=DwMD-g&c=qKdtBuuu6dQK9MsRUVJ2DPXW6oayO8fu4TfEHS8sGNk&r=9ngmsG8rSmDSS-O0b_V0gP-nN_33Vr52qbY3KXuDY5k&m=mcOOc8D0knaNNmmnTEo_F_WmT4j6_nUSL_yoPmGlLWQ&s=h7hQjqucR7tZyfZXxnoy3iitIr32YlrqiFyPATkW3lw&e=)\n",
    "* [Sci-kit Learn Linear Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "* [Sci-kit Learn Ensemble Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)\n",
    "* [Sci-kit Learn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "* [Sci-kit Learn Model Selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "* [Sci-kit Learn Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "* [Sci-kit Learn Preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THESE FIRST 3 IMPORTS ARE FROM FILES IN THE ML_PRACTICES FOLDER UNDER HW9\n",
    "# Use the versions found in the hw9 folder as some changes were made\n",
    "import visualize\n",
    "import metrics_plots\n",
    "from pipeline_components import DataSampleDropper, DataFrameSelector, DataScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re, os, pathlib\n",
    "import time as timelib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.externals import joblib\n",
    "import pickle as pkl\n",
    "\n",
    "FIGW = 5\n",
    "FIGH = 5\n",
    "FONTSIZE = 12\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (FIGW, FIGH)\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display current working directory of this notebook. If you are using \n",
    "relative paths for your data, then it needs to be relative to the CWD.\n",
    "\"\"\"\n",
    "HOME_DIR = pathlib.Path.home()\n",
    "pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set path appropriately. \n",
    "# data file can be found on canvas under Files/Homework Solutions, and on git\n",
    "# and the server under datasets/fraud_detection/\n",
    "fname = \"health_provider_fraud.csv\"\n",
    "claims_data = pd.read_csv(fname)\n",
    "claims_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display data info\n",
    "\"\"\"\n",
    "claims_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the head of the data\n",
    "\"\"\"\n",
    "claims_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the summary statistics\n",
    "Make sure you skim this\n",
    "\"\"\"\n",
    "claims_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Construct preprocessing pipeline\n",
    "\"\"\"\n",
    "selected_features = claims_data.columns\n",
    "scaled_features = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid',\n",
    "                   'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
    "                   'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt']\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('RowDropper', DataSampleDropper()),\n",
    "    ('FeatureSelector', DataFrameSelector(selected_features)),\n",
    "    ('Scale', DataScaler(scaled_features))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Pre-process the data using the defined pipeline\n",
    "\"\"\"\n",
    "processed_data = # TODO\n",
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Verify all NaNs removed\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Plot the class distributions for no potential fraud and potential fraud\n",
    "\"\"\"\n",
    "class_counts = pd.value_counts(processed_data['PotentialFraud'])\n",
    "class_counts.plot(kind='bar', rot=0, figsize=(10,3))\n",
    "plt.title(\"Potential Cases of Fraud\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Display the class fractions\n",
    "nsamples, nfeatures = processed_data.shape\n",
    "class_counts / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Extract positions of the postive and negative cases\n",
    "\"\"\"\n",
    "pos = processed_data['PotentialFraud'] == 1\n",
    "neg = processed_data['PotentialFraud'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Visualize the data using visualize.featureplots\n",
    "\"\"\"\n",
    "# Drop the provider name from the visualized data since it is not numeric\n",
    "cdata = processed_data.drop(['Provider'], axis=1).astype('float64')\n",
    "visualize.featureplots(cdata.values, cdata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Split data into X (the inputs) and y (the outputs)\n",
    "\n",
    "Hold out a subset of the data, before training and cross validation\n",
    "using train_test_split, with stratify NOT equal to None, and a test_size \n",
    "fraction of .2.\n",
    "\n",
    "For this exploratory section, the held out set of data is a validation set.\n",
    "For the GridSearch section, the held out set of data is a test set.\n",
    "\"\"\"\n",
    "targetnames = ['NonFraud', 'Fraud']\n",
    "\n",
    "# TODO: Separate the data into X and y\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Split data into train and test sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Play around with the hyper-parameters. Pick your favorite model to leave with in \n",
    "your submitted report.\n",
    "\"\"\"\n",
    "# TODO: Create and fit the model\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Predict with the model on the validation set\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Obtain prediction probabilities for the validation set, using \n",
    "# cross_val_predict with cv=10 and method='predict_proba'\n",
    "\n",
    "\n",
    "\n",
    "# TODO: The mean CV accuracy on the given validation data and labels, using \n",
    "# cross_val_score and cv=10\n",
    "scorescv = # TODO\n",
    "np.mean(scorescv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the confusion matrix, KS plot, ROC curve, and PR curve for the validation set\n",
    "using metrics_plots.ks_roc_prc_plot\n",
    "\n",
    "The red dashed line in the PRC is indicative of a the expected performance for a random\n",
    "classifier, which would predict predict postives at the rate of occurance within the data set\n",
    "\"\"\"\n",
    "# TODO: Confusion Matrix\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Curves\n",
    "# Note, you'll want the probability class predictions for the class label 1\n",
    "# See the API page for the DecisionTreeClassifier predict_proba; proba_val[:,1]\n",
    "\n",
    "\n",
    "\n",
    "# Obtain the PSS and F1 Score\n",
    "pss_val = metrics_plots.skillScore(ytest, preds_val)\n",
    "f1_val = f1_score(ytest, preds_val)\n",
    "print(\"PSS: %.4f\" % pss_val[0])\n",
    "print(\"F1 Score %.4f\" % f1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Export the image of the tree model\n",
    "use export_graphviz\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Estimated time: <10 min on mlserver\n",
    "Set up and run the grid search using GridSearchCV and the following \n",
    "settings:\n",
    "* The below scoring dictionary for scoring,\n",
    "* refit set to 'f1' as the optimized metric\n",
    "* Twenty for the number of cv folds, \n",
    "* n_jobs=3, \n",
    "* verbose=2, \n",
    "* return_train_score=True\n",
    "\"\"\"\n",
    "# Optimized metric\n",
    "opt_metric = 'f1'\n",
    "scoring = {opt_metric:opt_metric}\n",
    "\n",
    "# Flag to re-load previous run regardless of whether the file exists\n",
    "force = True\n",
    "# File previous run is saved to\n",
    "srchfname = \"hw9_search_\" + opt_metric + \".pkl\"\n",
    "\n",
    "# SETUP EXPERIMENT HYPERPARAMETERS\n",
    "max_depths = [None, 200, 100, 10, 8, 6, 4]\n",
    "max_leaf_nodes = [None, 10, 5, 2]\n",
    "\n",
    "ndepths = len(max_depths)\n",
    "nleaves = len(max_leaf_nodes)\n",
    "\n",
    "# TODO: Create the dictionary of hyper-parameters to try\n",
    "hyperparams = # TODO\n",
    "\n",
    "# RUN EXPERIMENT\n",
    "time0 = timelib.time()\n",
    "search = None\n",
    "if force or (not os.path.exists(srchfname)):\n",
    "    # TODO: Create the GridSearchCV object\n",
    "    search = # TODO\n",
    "\n",
    "    # TODO: Execute the grid search by calling fit using the training data\n",
    "\n",
    "    \n",
    "    # TODO: Save the grid search object\n",
    "\n",
    "    print(\"Saved %s\" % srchfname)\n",
    "else:\n",
    "    # TODO: Re-load the grid search object\n",
    "    \n",
    "    print(\"Loaded %s\" % srchfname)\n",
    "\n",
    "time1 = timelib.time()\n",
    "duration = time1 - time0\n",
    "print(\"Elapsed Time: %.2f min\" % (duration / 60))\n",
    "\n",
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the head of the results for the grid search\n",
    "See the cv_results_ attribute\n",
    "\"\"\"\n",
    "all_results = search.cv_results_\n",
    "df_res = pd.DataFrame(all_results)\n",
    "df_res.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Obtain the best model from the grid search and \n",
    "fit it to the full training data\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Export the image of the best model\n",
    "use export_graphviz\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the confusion matrix, KS plot, ROC curve, and PR curve for the test \n",
    "set using metrics_plots.ks_roc_prc_plot\n",
    "\n",
    "The red dashed line in the PRC is indicative of a the expected performance for\n",
    "a random classifier, which would predict predict postives at the rate of \n",
    "occurance within the data set\n",
    "\"\"\"\n",
    "# TODO: Predict with the best model on the test set\n",
    "\n",
    "\n",
    "# TODO: Obtain prediction probabilities for the test set using cross_val_predict\n",
    "# 'predict_proba' as the method\n",
    "\n",
    "\n",
    "# TODO: Compute mean accuracy (using cross_val_score) on the given test data and labels\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Confusion Matrix\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Curves (i.e. ROC, PRC, etc) use metrics_plots.ks_roc_prc_plot and the \n",
    "# the probabilities for the class label of 1\n",
    "\n",
    "\n",
    "\n",
    "# Obtain the PSS and F1 Score\n",
    "pss_test = metrics_plots.skillScore(ytest, preds_test)\n",
    "f1_test = f1_score(ytest, preds_test)\n",
    "print(\"PSS: %.4f\" % pss_test[0])\n",
    "print(\"F1 Score %.4f\" % f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Plot a histogram of the test scores from the best model.\n",
    "Compare the distribution of scores for positive and negative examples\n",
    "using boxplots.\n",
    "\n",
    "Create one subplot of the distribution of all the scores, with a histogram. \n",
    "Create a second subplot comparing the distribution of the scores of the \n",
    "positive examples with the distribution of the negative examples, with boxplots.\n",
    "\"\"\"\n",
    "# Obtain the pos and neg indices\n",
    "pos_inds = np.where(ytest)[0]\n",
    "neg_inds = np.where(ytest == 0)[0]\n",
    "\n",
    "# Separate the scores for the pos and neg examples\n",
    "proba_pos = proba_test[pos_inds, 1]\n",
    "proba_neg = proba_test[neg_inds, 1]\n",
    "\n",
    "# Plot the distribution of all scores\n",
    "nbins = 21\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(proba_neg, bins=nbins)\n",
    "plt.hist(proba_pos, bins=nbins)\n",
    "plt.xlabel('probability', fontsize=FONTSIZE)\n",
    "plt.ylabel('count', fontsize=FONTSIZE)\n",
    "plt.legend(['neg', 'pos'])\n",
    "\n",
    "# Plot the boxplots of the pos and neg examples\n",
    "plt.subplot(1,2,2)\n",
    "boxplot = plt.boxplot([proba_neg, proba_pos], patch_artist=True, sym='.')\n",
    "boxplot['boxes'][0].set_facecolor('pink')\n",
    "boxplot['boxes'][1].set_facecolor('lightblue')\n",
    "plt.xticks(ticks=[1, 2], labels=['-', '+'])\n",
    "plt.xlabel(\"Class\")\n",
    "plt.title(\"Model Probabilities for neg and pos examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "In 3 to 4 paragraphs, discuss and interpret the test results for the best model. Include a briefÂ discussion of the histogram and boxplots of the scores. Compare the best model from the grid search to the one you chose in the exploration section. Additionally, embed the image of the best tree model into the notebook using:  \n",
    "`<center><img src=\"path_to_model.png\"  style=\"width:100%;height:100%\">`  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
