{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NAME:__ __FULLNAME__  \n",
    "__SECTION:__ __NUMBER__  \n",
    "__CS 5970: Machine Learning Practices__\n",
    "\n",
    "# Homework 8: Support Vector Machines\n",
    "\n",
    "## Assignment Overview\n",
    "Follow the TODOs and read through and understand any provided code.  \n",
    "Post any questions regarding the assignment, to the Canvas discussion.\n",
    "For all plots, make sure all necessary axes and curves are clearly and \n",
    "accurately labeled. Include figure/plot titles appropriately as well.\n",
    "\n",
    "### Task\n",
    "For this assignment you will be exploring support vector machines (SVMs)\n",
    "using GridsearchCV and working with highly unbalanced datasets.\n",
    "\n",
    "\n",
    "### [Data set](https://canvas.ou.edu/courses/163924/files/folder/Homework%20Solutions)\n",
    "European Cardholder Credit Card Transactions, September 2013  \n",
    "This dataset presents transactions that occurred over two days. There were 492 incidents of \n",
    "frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class \n",
    "(frauds) accounts for 0.197% of all transactions.\n",
    "\n",
    "__Features__  \n",
    "* V1, V2, ... V28: are principal components obtained with PCA  \n",
    "* Time: the seconds elapsed between each transaction and the first transaction  \n",
    "* Amount: is the transaction Amount  \n",
    "* Class: the predicted variable; 1 in case of fraud and 0 otherwise.  \n",
    "\n",
    "Given the class imbalance ratio, it is recommended to use precision, recall and the \n",
    "Area Under the Precision-Recall Curve (AUPRC) to evaluate skill. Traditional accuracy \n",
    "and AUC are not meaningful for highly unbalanced classification. These scores are \n",
    "misleading due to the high impact of the large number of negative cases that can easily\n",
    "be identified. \n",
    "\n",
    "Examining precision and recall is more informative as these disregard the number of \n",
    "correctly identified negative cases (i.e. TN) and focus on the number of correctly \n",
    "identified positive cases (TP) and mis-identified negative cases (FP). Another useful \n",
    "metric is the F1 score which is the harmonic mean of the precision and recall; 1 is the \n",
    "best F1 score.\n",
    "\n",
    "Confusion Matrix  \n",
    "[TN  FP]  \n",
    "[FN  TP]\n",
    "\n",
    "Accuracy = $\\frac{TN + TP}{TN + TP + FN + FP}$  \n",
    "TPR = $\\frac{TP}{TP + FN}$  \n",
    "FPR = $\\frac{FP}{FP + TN}$  \n",
    "\n",
    "Recall = TPR = $\\frac{TP}{TP + FN}$  \n",
    "Precision = $\\frac{TP}{TP + FP}$  \n",
    "F1 Score = 2 * $\\frac{precision * recall}{precision + recall}$  \n",
    "\n",
    "See the references below for more details on precision, recall, and the F1 score.\n",
    "\n",
    "\n",
    "The dataset was collected and analysed during a research collaboration of \n",
    "Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Universit√© \n",
    "Libre de Bruxelles) on big data mining and fraud detection [1]\n",
    "\n",
    "[1] Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi.\n",
    "Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium\n",
    "on Computational Intelligence and Data Mining (CIDM), IEEE, 2015.\n",
    "http://mlg.ulb.ac.be/BruFence . http://mlg.ulb.ac.be/ARTML\n",
    "\n",
    "\n",
    "### Objectives\n",
    "* Understanding Support Vector Machines\n",
    "* GridSearch with Classification\n",
    "* Creating Scoring functions\n",
    "* Stratification\n",
    "\n",
    "### Notes\n",
    "* Do not save work within the ml_practices folder\n",
    "\n",
    "### General References\n",
    "* [Guide to Jupyter](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)\n",
    "* [Python Built-in Functions](https://docs.python.org/3/library/functions.html)\n",
    "* [Python Data Structures](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n",
    "* [Numpy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)\n",
    "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n",
    "* [DataCamp: Matplotlib](https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python?utm_source=adwords_ppc&utm_campaignid=1565261270&utm_adgroupid=67750485268&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=1t1&utm_creative=332661264365&utm_targetid=aud-299261629574:dsa-473406587955&utm_loc_interest_ms=&utm_loc_physical_ms=9026223&gclid=CjwKCAjw_uDsBRAMEiwAaFiHa8xhgCsO9wVcuZPGjAyVGTitb_-fxYtkBLkQ4E_GjSCZFVCqYCGkphoCjucQAvD_BwE)\n",
    "* [Pandas DataFrames](https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_reference_api_pandas.DataFrame.html&d=DwMD-g&c=qKdtBuuu6dQK9MsRUVJ2DPXW6oayO8fu4TfEHS8sGNk&r=9ngmsG8rSmDSS-O0b_V0gP-nN_33Vr52qbY3KXuDY5k&m=mcOOc8D0knaNNmmnTEo_F_WmT4j6_nUSL_yoPmGlLWQ&s=h7hQjqucR7tZyfZXxnoy3iitIr32YlrqiFyPATkW3lw&e=)\n",
    "* [Sci-kit Learn Linear Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "* [Sci-kit Learn Ensemble Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)\n",
    "* [Sci-kit Learn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "* [Sci-kit Learn Model Selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "* [Scoring Parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "* [Scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring)\n",
    "* [Plot ROC](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)\n",
    "* [Precision, Recall, F1 Score](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "* [Precision-Recall Curve](https://acutecaretesting.org/en/articles/precision-recall-curves-what-are-they-and-how-are-they-used)\n",
    "* [Probability Plot](https://www.itl.nist.gov/div898/handbook/eda/section3/normprpl.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THESE FIRST 3 IMPORTS ARE CUSTOM .py FILES AND CAN BE FOUND ON THE SERVER\n",
    "# AND GIT\n",
    "import visualize\n",
    "import metrics_plots\n",
    "from pipeline_components import DataSampleDropper, DataFrameSelector\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import os, re, fnmatch\n",
    "import pathlib, itertools\n",
    "import time as timelib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import floor, ceil\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import learning_curve, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "HOME_DIR = pathlib.Path.home()\n",
    "CW_DIR = pathlib.Path.cwd()\n",
    "\n",
    "FIGW = 12\n",
    "FIGH = 5\n",
    "FONTSIZE = 8\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (FIGW, FIGH)\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can download the full dataset from Canvas under Files/Homework Solutions\n",
    "# TODO: set appropriately\n",
    "filename = 'anomaly_detection/creditcard.csv'\n",
    "\n",
    "crime_stats_full = pd.read_csv(filename)\n",
    "crime_stats_full.dataframeName = 'creditcard.csv'\n",
    "nRows, nCols = crime_stats_full.shape\n",
    "print(f'There are {nRows} rows and {nCols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "good (negative case = 0)\n",
    "fraud (positive case = 1)\n",
    "\"\"\"\n",
    "targetnames = ['good', 'fraud']\n",
    "\n",
    "pos_full = crime_stats_full.loc[crime_stats_full['Class'] == 1] \n",
    "neg_full = crime_stats_full.loc[crime_stats_full['Class'] == 0] \n",
    "\n",
    "pos_full.shape, neg_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Compute the postive fraction\n",
    "\"\"\"\n",
    "pos_fraction = pos_full.shape[0] / nRows\n",
    "neg_fraction = 1 - pos_fraction\n",
    "\n",
    "pos_fraction, neg_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Select Random Subset of data\n",
    "\"\"\"\n",
    "np.random.seed(42)\n",
    "subset_size = 20000\n",
    "selected_indices = np.random.choice(range(nRows), size=subset_size, replace=False)\n",
    "selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "List the features and shape of the data\n",
    "\"\"\"\n",
    "crime_stats = crime_stats_full.loc[selected_indices, :]\n",
    "crime_stats.columns, crime_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display whether there are any NaNs\n",
    "\"\"\"\n",
    "crime_stats.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display summary statistics for each feature of the dataframe\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the distributions of the data\n",
    "use visualize.featureplots(crime_stats_dropna.values, crime_stats.columns)\n",
    "to generate trace plots, histograms, boxplots, and probability plots for\n",
    "each feature.\n",
    "\n",
    "A probability plot is utilized to evaulate the normality of a distribution.\n",
    "The data are plot against a theoritical distribution, such that if the data \n",
    "are normal, they'll follow the diagonal line. See the reference above for \n",
    "more information.\n",
    "\"\"\"\n",
    "crime_stats_dropna = crime_stats.dropna()\n",
    "# TODO: visualize the features\n",
    "\n",
    "\n",
    "# Right click to enable scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the Pearson correlation between all pairs of the features\n",
    "use visualize.scatter_corrplots(crime_stats_dropna.values, crime_stats.columns, corrfmt=\"%.1f\", FIGW=15)\n",
    "\"\"\"\n",
    "visualize.scatter_corrplots(crime_stats_dropna.values, crime_stats.columns, corrfmt=\"%.1f\", FIGW=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Separate the postive and negative examples\n",
    "\"\"\"\n",
    "pos = crime_stats.loc[crime_stats['Class'] == 1] \n",
    "neg = crime_stats.loc[crime_stats['Class'] == 0] \n",
    "\n",
    "pos.shape, neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Compute the postive fraction\n",
    "\"\"\"\n",
    "pos_fraction = pos.shape[0] / nRows\n",
    "neg_fraction = 1 - pos_fraction\n",
    "\n",
    "pos_fraction, neg_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Compare the features for the positive and negative examples\n",
    "\"\"\"\n",
    "features_displayed = pos.columns\n",
    "ndisplayed = len(features_displayed)\n",
    "ncols = 5\n",
    "nrows = ceil(ndisplayed / ncols)\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n",
    "fig.subplots_adjust(wspace=.5, hspace=.5)\n",
    "axs = axs.ravel()\n",
    "for ax, feat_name in zip(axs, features_displayed):\n",
    "    boxplot = ax.boxplot([neg[feat_name], pos[feat_name]], patch_artist=True, sym='.')\n",
    "    boxplot['boxes'][0].set_facecolor('pink')\n",
    "    boxplot['boxes'][1].set_facecolor('lightblue')\n",
    "    ax.set_xticklabels(['-', '+'])\n",
    "    ax.set(title=feat_name)\n",
    "\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Clean Up and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Construct Pipeline to pre-process data\n",
    "\"\"\"\n",
    "feature_names = crime_stats.columns.drop(['Class'])\n",
    "pipe_X = Pipeline([\n",
    "    (\"NaNrowDropper\", DataSampleDropper()),\n",
    "    (\"selectAttribs\", DataFrameSelector(feature_names)),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "pipe_y = Pipeline([\n",
    "    (\"NaNrowDropper\", DataSampleDropper()),\n",
    "    (\"selectAttribs\", DataFrameSelector(['Class']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Pre-process the data using the pipeliine\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "np.any(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Re-visualize the pre-processed data\n",
    "use visualize.featureplots()\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs: EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Hold out a subset of the data, before training and cross validation\n",
    "using train_test_split, with stratify NOT equal to None, and a test_size \n",
    "fraction of .2.\n",
    "\n",
    "For this exploratory section, the held out set of data is a validation set.\n",
    "For the GridSearch section, the held out set of data is a test set.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Create and train SVC models. \n",
    "Explore various configurations of the hyper-parameters. \n",
    "Train the models on the training set and evaluate them for the training and\n",
    "validation sets.\n",
    "\n",
    "Play around with C, gamma, and class_weight. Feel free to play with other hyper-\n",
    "parameters as well. See the API for more details.\n",
    "C is a regularization parameter, gamma is the inverse of the radius of influence\n",
    "of the support vectors (i.e. lower gamma means a higher radius of influence of the \n",
    "support vectors), and class weight determines whether to adjust the weights inversely\n",
    "to the class fractions.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Evaluate training set performance. \n",
    "Display the confusion matrix, KS plot with\n",
    "the cumulative distributions of the TPR and FPR, the ROC curve and the \n",
    "precision-recall curve (PRC). use metrics_plots.ks_roc_prc_plot(ytrue, scores)\n",
    "\n",
    "The PRC, unlike the AUC, does not consider the true negative (i.e. TN) counts,\n",
    "making the PRC more robust to unbalanced datasets.\n",
    "\"\"\"\n",
    "# TODO: Confusion matrix\n",
    "# First, compute the predictions for the training set\n",
    "# Second, use confusion_matrix\n",
    "# Third, use metrics_plots.confusion_mtx_colormap() to display the matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Curves\n",
    "# First, use the model's decision function to compute the scores\n",
    "# Second, use metrics_plots.ks_roc_prc_plot() to display the KS plot, ROC, and PRC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pss_train = metrics_plots.skillScore(ytrain.values, preds)\n",
    "f1_train = f1_score(ytrain.values.ravel(), preds)\n",
    "print(\"PSS: %.4f\" % pss_train[0])\n",
    "print(\"F1 Score %.4f\" % f1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Evaluate validation performance. \n",
    "Display the confusion matrix, KS plot with the cumulative distributions of the TPR \n",
    "and FPR, the ROC curve and the precision-recall curve (PRC).\n",
    "\"\"\"\n",
    "# TODO: Confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Curves\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pss_test = metrics_plots.skillScore(ytest.values, preds_test)\n",
    "f1_test = f1_score(ytest.values.ravel(), preds_test)\n",
    "print(\"PSS: %.4f\" % pss_test[0])\n",
    "print(\"F1 Score %.4f\" % f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs: STRATIFIED GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "List of available scoring functions from the sklearn module\n",
    "\"\"\"\n",
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Estimated time: ~30 min on mlserver\n",
    "Set up and run the grid search using GridSearchCV and the following \n",
    "settings:\n",
    "* SVC for the model,\n",
    "* The above scoring dictionary for scoring,\n",
    "* refit set to 'f1' as the optimized metric\n",
    "* Three for the number of cv folds, \n",
    "* n_jobs=3, \n",
    "* verbose=2, \n",
    "* return_train_score=True\n",
    "\"\"\"\n",
    "# Optimized metric\n",
    "opt_metric = 'f1'\n",
    "scoring = {'f1':'f1'}\n",
    "\n",
    "# Flag to re-load previous run\n",
    "force = False\n",
    "# File previous run is saved to\n",
    "srchfname = \"hw8_search_\" + opt_metric + \".pkl\"\n",
    "\n",
    "# SETUP EXPERIMENT HYPERPARAMETERS\n",
    "Cs = [.5, 1, 10, 100, 200]\n",
    "gammas = np.logspace(-4, 0, num=5, endpoint=True, base=5)\n",
    "\n",
    "nCs = len(Cs)\n",
    "ngammas = len(gammas)\n",
    "\n",
    "hyperparams = {'C':Cs, 'gamma':gammas, 'tol':[1e-4],\n",
    "               'class_weight':[None, 'balanced']}\n",
    "\n",
    "# RUN EXPERIMENT\n",
    "time0 = timelib.time()\n",
    "search = None\n",
    "if force or (not os.path.exists(srchfname)):\n",
    "    # TODO: Create the GridSearchCV object\n",
    "    search = # TODO\n",
    "    \n",
    "    # TODO: Execute the grid search by calling fit using the training data\n",
    "    \n",
    "    \n",
    "    # TODO: Save the grid search object\n",
    "\n",
    "    \n",
    "    print(\"Saved %s\" % srchfname)\n",
    "else:\n",
    "    search = joblib.load(srchfname)\n",
    "    print(\"Loaded %s\" % srchfname)\n",
    "\n",
    "time1 = timelib.time()\n",
    "duration = time1 - time0\n",
    "print(\"Elapsed Time: %.2f min\" % (duration / 60))\n",
    "\n",
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the head of the results for the grid search\n",
    "See the cv_results_ attribute\n",
    "\"\"\"\n",
    "all_results = search.cv_results_\n",
    "df_res = pd.DataFrame(all_results)\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Plot the mean training and validation results from the grid search as a\n",
    "colormap, for C (y-axis) vs the gamma (x-axis), for class_weight=None\n",
    "\"\"\"\n",
    "results_grid_train = df_res['mean_train_'+opt_metric].values.reshape(nCs, 2, ngammas)\n",
    "results_grid_val = df_res['mean_test_'+opt_metric].values.reshape(nCs, 2, ngammas)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6,6))\n",
    "fig.subplots_adjust(wspace=.45)\n",
    "axs = axs.ravel()\n",
    "means = [(\"Training\", results_grid_train),\n",
    "         (\"Validation\", results_grid_val)]\n",
    "for i, (name, result) in enumerate(means):\n",
    "    img = axs[i].imshow(result[:,0,:], cmap=\"jet\", vmin=0, vmax=1)\n",
    "    axs[i].set_title(name)\n",
    "    axs[i].set_xticks(range(ngammas))\n",
    "    axs[i].set_yticks(range(nCs))\n",
    "    axs[i].set_xticklabels(np.around(gammas, 3))\n",
    "    axs[i].set_yticklabels(np.around(Cs, 3))\n",
    "    axs[i].figure.colorbar(img, ax=axs[i], label=opt_metric, \n",
    "                           orientation='horizontal')\n",
    "    if i == 0:\n",
    "        axs[i].set_xlabel(r\"$\\gamma$\")\n",
    "        axs[i].set_ylabel(\"C\")\n",
    "#fig.suptitle('class_weight=None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Obtain the best model from the grid search and \n",
    "fit it to the full training data\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "For the best model, display the confusion matrix, KS plot, ROC curve, \n",
    "and PR curve for the training set\n",
    "\"\"\"\n",
    "# TODO: Confusion Matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Curves\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pss_res = metrics_plots.skillScore(ytrain.values, preds)\n",
    "f1_res = f1_score(ytrain.values.ravel(), preds)\n",
    "print(\"PSS: %.4f\" % pss_res[0])\n",
    "print(\"F1 Score %.4f\" % f1_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "For the best model, display the confusion matrix, KS plot, ROC curve, \n",
    "and PR curve for the test set\n",
    "\"\"\"\n",
    "# TODO: Confustion Matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Curves\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pss_res_test = metrics_plots.skillScore(ytest.values, preds_test)\n",
    "f1_res_test = f1_score(ytest.values.ravel(), preds_test)\n",
    "print(\"PSS: %.4f\" % pss_res_test[0])\n",
    "print(\"F1 Score %.4f\" % f1_res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Plot a histogram of the test scores from the best model.\n",
    "Compare the distribution of scores for positive and negative examples\n",
    "using boxplots.\n",
    "\n",
    "Create one subplot of the distribution of all the scores, with a histogram. \n",
    "Create a second subplot comparing the distribution of the scores of the \n",
    "positive examples with the distribution of the negative examples, with boxplots.\n",
    "\"\"\"\n",
    "# TODO: Obtain the indices of the pos and neg examples\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Separate the scores for the pos and neg examples\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Plot the distribution of all scores\n",
    "nbins = 41\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Plot the boxplots of the pos and neg examples' scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "In 3 to 4 paragraphs, discuss and interpret the test results for the best model. Include a brief¬†discussion of the difference in the meaning of the AUC for the ROC vs the AUC for the PRC. Also, discuss the histogram and boxplots of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
