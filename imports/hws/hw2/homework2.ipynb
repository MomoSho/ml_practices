{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAME: __FULLNAME__\n",
    "\n",
    "# Homework 2\n",
    "\n",
    "### Objectives\n",
    "* Object orientation in Python\n",
    "* Constructing Data Pre-processing Pipelines\n",
    "  + Imputing\n",
    "  + Filtering\n",
    "  + Simple Numerical Methods\n",
    "* Do not save work within the ml_practices folder\n",
    "  + create a folder in your home directory for assignments, and copy the templates there  \n",
    "\n",
    "### General References\n",
    "* [Sci-kit Learn Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "* [Sci-kit Learn Impute](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute)\n",
    "* [Sci-kit Learn Preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
    "* [Pandas Interpolate](https://pandas.pydata.org/pandas-docs/version/0.16/generated/pandas.DataFrame.interpolate.html)\n",
    "* [Pandas fillna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "FIGWIDTH = 10\n",
    "FIGHEIGHT = 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '~/ml_practices/imports/datasets/baby1/subject_k1_w10_hw2.csv'\n",
    "baby_data_raw = # TODO\n",
    "baby_data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Call describe() on the data to get summary statistics\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Call head() on the data to observe the first few examples\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Call tail() on the data to observe the last few examples\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the column names for the data\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Determine whether any data are NaN. Use isna() and\n",
    "any() to obtain a summary of which features have at \n",
    "least one missing value\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pipeline Elements\n",
    "In the lecture, some of the Pipeline components might have taken in or returned numpy arrays and others pandas DataFrames. For this assignment, transform methods for all the Pipeline components will take input as a pandas DataFrame and return a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Pipeline component object for selecting a subset of specified features\n",
    "\"\"\"\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs):\n",
    "        self.attribs = attribs\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        PARAMS:\n",
    "            X: is a DataFrame\n",
    "        RETURNS: a DataFrame of the selected attributes\n",
    "        '''\n",
    "        return X[self.attribs]\n",
    "\n",
    "\n",
    "\"\"\" TODO\n",
    "Complete the Pipeline component object for interpolating and filling in \n",
    "gaps within the data. Whenever data are missing inbetween valid values, \n",
    "use interpolation to fill in the gaps. For example,\n",
    "    1.2 NaN NaN 1.5 \n",
    "becomes\n",
    "    1.2 1.3 1.4 1.5 \n",
    "\n",
    "Whenever data are missing on the edges of the data, fill in the gaps\n",
    "with the first available valid value. For example,\n",
    "    NaN NaN 2.3 3.6 3.2 NaN\n",
    "becomes\n",
    "    2.3 2.3 2.3 3.6 3.2 3.2\n",
    "The transform() method should fill in the holes and the edge cases.\n",
    "\"\"\"\n",
    "class InterpolationImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, method='quadratic'):\n",
    "        self.method = method\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X): # TODO\n",
    "        '''\n",
    "        PARAMS:\n",
    "            X: is a DataFrame\n",
    "        RETURNS: a DataFrame without NaNs\n",
    "        '''\n",
    "        # TODO: Interpolate holes within the data\n",
    "        \n",
    "        # TODO: Fill in the NaNs on the edges of the data\n",
    "                \n",
    "        # TODO: return the imputed dataframe\n",
    "\n",
    "\n",
    "\"\"\" TODO\n",
    "Complete the Pipeline component object for smoothing specific features\n",
    "using a gaussian kernel. Use the following formula to apply the filter:\n",
    "    x'[t] = ( w[0]*x[t-3] + w[1]*x[t-2] + w[2]*x[t-1] + w[3]*x[t]\n",
    "           + w[4]*x[t+1] + w[5]*x[t+2] + w[6]*x[t+3])\n",
    "    DISCLAIMER: if you implement this computation on more than one line, \n",
    "                make sure to place parentheses around the entire expression \n",
    "                such that the interpreter reads the lines as all part of \n",
    "                one expression\n",
    "This can be implemented similarly to how the derivative is computed. \n",
    "Additionally, pad both ends of x with three instances of the adjacent\n",
    "value, before filtering, to maintain the original signal length and \n",
    "smoothness. For example,\n",
    "                1.3 2.1 4.4 4.1 3.2\n",
    "would be padded as\n",
    "    1.3 1.3 1.3 1.3 2.1 4.4 4.1 3.2 3.2 3.2 3.2\n",
    "\"\"\"\n",
    "\n",
    "def computeweights(length=3, sig=1):\n",
    "    '''\n",
    "    Computes the weights for a Gaussian filter kernel\n",
    "    PARAMS:\n",
    "        length: the number of terms in the filter kernel\n",
    "        sig: the standard deviation (i.e. the scale) of the Gaussian\n",
    "    RETURNS: a list of filter weights for the Gaussian kernel\n",
    "    '''\n",
    "    x = np.linspace(-2.5, 2.5, length)\n",
    "    kernel = stats.norm.pdf(x, scale=sig)\n",
    "    return kernel / kernel.sum()\n",
    "\n",
    "class GaussianFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs=None, kernelsize=3, sig=1):\n",
    "        self.attribs = attribs\n",
    "        self.kernelsize = kernelsize\n",
    "        self.sig = sig\n",
    "        self.weights = computeweights(length=kernelsize, sig=sig)\n",
    "        print(\"KERNEL WEIGHTS\", self.weights)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X): # TODO\n",
    "        '''\n",
    "        PARAMS:\n",
    "            X: is a DataFrame\n",
    "        RETURNS: a DataFrame with the smoothed signals\n",
    "        '''\n",
    "        w = self.weights\n",
    "        Xout = X.copy()\n",
    "        if self.attribs == None:\n",
    "            self.attribs = Xout.columns\n",
    "        \n",
    "        # TODO for each attribute:\n",
    "            # TODO: pad the data\n",
    "            \n",
    "            # TODO: filter the data\n",
    "                        \n",
    "        # TODO: return filtered dataframe\n",
    "\n",
    "\n",
    "\"\"\" PROVIDED\n",
    "Pipeline component object for computing the derivative for specified features\n",
    "\"\"\"\n",
    "class DerivativeComputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs=None, prefix='d_', dt=1.0):\n",
    "        self.attribs = attribs\n",
    "        self.prefix = prefix\n",
    "        self.dt = dt\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        PARAMS:\n",
    "            X: is a DataFrame\n",
    "        RETURNS: a DataFrame with additional features for the derivatives\n",
    "        '''\n",
    "        Xout = X.copy()\n",
    "        if self.attribs == None:\n",
    "            self.attribs = Xout.columns\n",
    "        \n",
    "        for attrib in self.attribs:\n",
    "            vals = Xout[attrib].values\n",
    "            diff = vals[1:] - vals[0:-1]\n",
    "            deriv = diff / self.dt\n",
    "            deriv = np.append(deriv, 0)\n",
    "            attrib_name = self.prefix + attrib\n",
    "            Xout[attrib_name] = pd.Series(deriv)\n",
    "\n",
    "        return Xout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_names = ['left_wrist_x', 'left_wrist_y', 'left_wrist_z']\n",
    "selected_inds = [baby_data_raw.columns.get_loc(name) for name in selected_names]\n",
    "nselected = len(selected_names)\n",
    "time = baby_data_raw['time'].values\n",
    "Xsel_raw = baby_data_raw[selected_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Create a pipeline that:\n",
    "1. Selects a subset of features\n",
    "2. Fills gaps within the data by linearly interpolating the values \n",
    "   in between existing data and fills the remaining gaps at the edges\n",
    "   of the data with the first or last valid value\n",
    "3. Compute the derivatives of the selected features. The data are \n",
    "   sampled at 50 Hz, therefore, the period or elapsed time (dt) between \n",
    "   the samples is .02 seconds (dt=.02)\n",
    "\"\"\"\n",
    "pipe1 = # TODO\n",
    "\n",
    "\"\"\" TODO\n",
    "Create a pipeline that:\n",
    "1. Selects a subset of features\n",
    "2. Fills gaps within the data by linearly interpolating the values \n",
    "   in between existing data and fills the remaining gaps at the edges\n",
    "   of the data with the first or last valid value\n",
    "3. Smooth the data with a Gaussian Filter. Use a standard deviation \n",
    "   of 2 and a kernel size of 7 for the filter\n",
    "4. Compute the derivatives of the selected features. The data are \n",
    "   sampled at 50 Hz, therefore, the period or elapsed time (dt) between \n",
    "   the samples is .02 seconds (dt=.02)\n",
    "\"\"\"\n",
    "pipe2 = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Fit both Pipelines to the data and transform the data\n",
    "\"\"\"\n",
    "baby_data1 = # TODO\n",
    "baby_data2 = # TODO\n",
    "\n",
    "\"\"\" TODO\n",
    "Display the summary statistics for the pre-processed data\n",
    "from both pipelines\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the first few values for the pre-processed data\n",
    "from both pipelines\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the last few values for the pre-processed data\n",
    "from both pipelines\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Construct plots comparing the raw data to the pre-processed data \n",
    "for each selected feature from both pipelines. For each selected \n",
    "feature, create a figure displaying the raw data andthe cleaned \n",
    "data in the same subplot. The raw data should be shifted upwards \n",
    "to clearly observe where the gaps are filled in the cleaned data. \n",
    "There should be three subplots per feature figure. Each subplot \n",
    "is in a separate row.\n",
    "    subplot(1) will compare the original raw data to the pipeline1 \n",
    "               pre-processed data\n",
    "    subplot(2) will compare the original raw data to the pipeline2 \n",
    "               pre-processed data\n",
    "    subplot(3) will compare pipeline1 to pipeline2. Set the x limit \n",
    "               to 45 and 55 seconds\n",
    "For all subplots, include axis labels, legends and titles.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Construct plots for each feature presenting the feature and its \n",
    "derivative from both pipelines. Each figure should have \n",
    "3 subplots:\n",
    "    1: the pipeline1 feature data and cooresponding derivative \n",
    "    2: the pipeline2 feature data and corresponding derivative\n",
    "    3: pipeline1 derivative and pipeline2 derivative. Set the x limit \n",
    "       to 8 and 12 seconds.\n",
    "For all subplots, include axis labels, legends and titles.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
