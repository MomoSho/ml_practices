{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NAME:__ __FULLNAME__  \n",
    "__SECTION:__ __NUMBER__  \n",
    "__CS 5970: Machine Learning Practices__\n",
    "\n",
    "# Homework 5: Regularization\n",
    "\n",
    "## Assignment Overview\n",
    "Follow the TODOs and read through and understand any provided code.  \n",
    "For all plots, make sure all necessary axes and curves are clearly and \n",
    "accurately labeled. Include figure/plot titles appropriately as well.\n",
    "\n",
    "### Task\n",
    "For this assignment you will be exploring regularization. Regularization\n",
    "is a powerful tool in machine learning to impose rational constraints on \n",
    "models during the training process to mitigate overfitting to the training \n",
    "set and improve model generalization. By including one or more terms within\n",
    "the cost function to penalize the weights, the learning algorithm will try \n",
    "to fit the data while avoiding certain values for the weights that might \n",
    "overfit the data.\n",
    "\n",
    "\n",
    "### Data set\n",
    "The BMI data will be utilized. Recall: \n",
    "* _MI_ files contain data with the number of action potentials for 48 neurons, at mutliple \n",
    "time points, for a single fold. There are 20 folds (20 files), where each fold consists \n",
    "of over 1000 times points (the rows). At each time point, we record the number of \n",
    "activations for each neuron for 20 bins. Therefore, each time point has 48 * 20 = 960 \n",
    "columns.  \n",
    "* _theta_ files record the angular position of the shoulder (in column 0) and the elbow \n",
    "(in column 1) for each time point (in radians).  \n",
    "* _dtheta_ files record the angular velocity of the shoulder (in column 0) and the elbow \n",
    "(in column 1) for each time point (in radians/sec).  \n",
    "* _torque_ files record the torque of the shoulder (in column 0) and the elbow (in column \n",
    "1) for each time point (N-m).  \n",
    "* _time_ files record the actual time stamp of each time point (seconds).  \n",
    "\n",
    "This assignment utilizes code examples and concepts from the lectures on Sept 19 - Oct 1.\n",
    "\n",
    "### Objectives\n",
    "* Use and understand regularization in regression\n",
    "* Learn to select hyper-parameters to tune model behavior, specifically:\n",
    "    * Regularization parameters\n",
    "    * Training set size\n",
    "\n",
    "### Notes\n",
    "* Do not save work within the ml_practices folder\n",
    "\n",
    "### General References\n",
    "* [Python Built-in Functions](https://docs.python.org/3/library/functions.html)\n",
    "* [Python Data Structures](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n",
    "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n",
    "* [Pandas DataFrames](https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_reference_api_pandas.DataFrame.html&d=DwMD-g&c=qKdtBuuu6dQK9MsRUVJ2DPXW6oayO8fu4TfEHS8sGNk&r=9ngmsG8rSmDSS-O0b_V0gP-nN_33Vr52qbY3KXuDY5k&m=mcOOc8D0knaNNmmnTEo_F_WmT4j6_nUSL_yoPmGlLWQ&s=h7hQjqucR7tZyfZXxnoy3iitIr32YlrqiFyPATkW3lw&e=)\n",
    "* [Sci-kit Learn Linear Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "* [Sci-kit Learn Ensemble Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)\n",
    "* [Sci-kit Learn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "* [Sci-kit Learn Model Selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re, fnmatch, time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "FIGWIDTH = 6\n",
    "FIGHEIGHT = 6\n",
    "FONTSIZE = 10\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (FIGWIDTH, FIGHEIGHT)\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bmi_file_set(directory, filebase):\n",
    "    '''\n",
    "    Read a set of CSV files and append them together\n",
    "    :param directory: The directory in which to scan for the CSV files\n",
    "    :param filebase: A file specification that potentially includes wildcards\n",
    "    :returns: A list of Numpy arrays (one for each fold)\n",
    "    '''\n",
    "    \n",
    "    # The set of files in the directory\n",
    "    files = fnmatch.filter(os.listdir(directory), filebase)\n",
    "    files.sort()\n",
    "\n",
    "    # Create a list of Pandas objects; each from a file in the directory that matches filebase\n",
    "    lst = [pd.read_csv(directory + \"/\" + file, delim_whitespace=True).values for file in files]\n",
    "    \n",
    "    # Concatenate the Pandas objects together.  ignore_index is critical here so that\n",
    "    # the duplicate row indices are addressed\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Load the BMI data from all the folds, using read_bmi_file_set()\n",
    "\"\"\"\n",
    "dir_name = '../ml_practices/imports/datasets/bmi/DAT6_08' # TODO: make sure to set this appropriately\n",
    "MI_folds = read_bmi_file_set(dir_name, 'MI_fold*')\n",
    "theta_folds = read_bmi_file_set(dir_name, 'theta_fold*')\n",
    "dtheta_folds = read_bmi_file_set(dir_name, 'dtheta_fold*')\n",
    "torque_folds = read_bmi_file_set(dir_name, 'torque_fold*')\n",
    "time_folds = read_bmi_file_set(dir_name, 'time_fold*')\n",
    "\n",
    "alldata_folds = zip(MI_folds, theta_folds, dtheta_folds, torque_folds, time_folds)\n",
    "\n",
    "nfolds = len(MI_folds)\n",
    "nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print out the shape of all the data for each fold\n",
    "\"\"\"\n",
    "for i, (MI, theta, dtheta, torque, time) in enumerate(alldata_folds):\n",
    "    print(\"FOLD %2d \" % i, MI.shape, theta.shape, dtheta.shape, torque.shape, time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Print out the first few examples of the theta data\n",
    "for a few folds\n",
    "\"\"\"\n",
    "for i, theta in enumerate(theta_folds[:3]):\n",
    "    print(\"FOLD %2d\" % i)\n",
    "    print(theta[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check the data for any NaNs\n",
    "\"\"\"\n",
    "def anynans(X):\n",
    "    return np.isnan(X).any()\n",
    "\n",
    "alldata_folds = zip(MI_folds, theta_folds, dtheta_folds, torque_folds, time_folds)\n",
    "\n",
    "for i, (MI, theta, dtheta, torque, time) in enumerate(alldata_folds):\n",
    "    print(\"FOLD %2d \" % i, anynans(MI), anynans(theta), anynans(dtheta), anynans(torque), anynans(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGULARIZED REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Evaluate the training performance of an already trained model\n",
    "\"\"\"\n",
    "def mse_rmse(trues, preds):\n",
    "    '''\n",
    "    Compute MSE and rMSE for each column separately.\n",
    "    '''\n",
    "    mse = np.sum(np.square(trues - preds), axis=0) / trues.shape[0]\n",
    "    rmse_rads = np.sqrt(mse)\n",
    "    rmse_degs = rmse_rads * 180 / np.pi\n",
    "    return mse, rmse_rads, rmse_degs\n",
    "\n",
    "def predict_score_eval(model, X, y):\n",
    "    '''\n",
    "    Compute the model predictions and cooresponding scores.\n",
    "    PARAMS:\n",
    "        X: feature data\n",
    "        y: cooresponding output\n",
    "    RETURNS:\n",
    "        mse: mean squared error for each column\n",
    "        rmse_rads: rMSE in radians\n",
    "        rmse_deg: rMSE in degrees\n",
    "        score: score computed by the models score() method\n",
    "        preds: predictions of the model from X\n",
    "    '''\n",
    "    \n",
    "    # TODO: place implementation from HW4 here\n",
    "    \n",
    "    return mse, rmse_rads, rmse_degs, score, preds\n",
    "\n",
    "\n",
    "\"\"\" TODO\n",
    "Create scoring function object for gridsearch\n",
    "\n",
    "This represents a more general way of creating a scoring mechanism than\n",
    "what was discussed in the lectures.\n",
    "\n",
    "GridSearchCV: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "make_scorer: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html\n",
    "\n",
    "\"\"\"\n",
    "def rmse_deg_scorer(trues, preds):\n",
    "    '''\n",
    "    Compute rMSE in degrees\n",
    "    '''\n",
    "    _, _, rmse_degs = mse_rmse(trues, preds)\n",
    "    return # TODO: return the rMSE in degrees \n",
    "\n",
    "# Make the scoring function for GridSearch\n",
    "rmse_deg_scoring = make_scorer(rmse_deg_scorer, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Construct training set to obtain best model and testing set for \n",
    "evaluation. The model will focus on predicting the elbow torque.\n",
    "\"\"\"\n",
    "# Extract fold indices for the training and testing sets\n",
    "trainset_fold_inds = [5, 6] \n",
    "testset_fold_inds = [8, 9] \n",
    "\n",
    "# Combine the folds into singular numpy arrays\n",
    "# Training set\n",
    "MI_trainset = [MI_folds[f] for f in trainset_fold_inds]\n",
    "torque_trainset = [torque_folds[f] for f in trainset_fold_inds]\n",
    "time_trainset = [time_folds[f] for f in trainset_fold_inds]\n",
    "\n",
    "X = np.concatenate(MI_trainset, axis=0)\n",
    "y = np.concatenate(torque_trainset, axis=0)[:,0]\n",
    "time = np.concatenate(time_trainset, axis=0)\n",
    "\n",
    "# Testing set\n",
    "MI_testset = [MI_folds[f] for f in testset_fold_inds]\n",
    "torque_testset = [torque_folds[f] for f in testset_fold_inds]\n",
    "time_testset = [time_folds[f] for f in testset_fold_inds]\n",
    "\n",
    "Xtest = np.concatenate(MI_testset, axis=0)\n",
    "ytest = np.concatenate(torque_testset, axis=0)[:,0]\n",
    "time_test = np.concatenate(time_testset, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape, Xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Construct and train the default linear model using the training set.\n",
    "Display the Training and Testing rMSEs in degrees.\n",
    "You can use the rmse_deg_scorer for this.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search and ElasticNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Specify the parameter search grid as a dictionary, and display it\n",
    "\"\"\"\n",
    "alphas = np.logspace(-10, 9, base=2, num=9, endpoint=True)\n",
    "l1_ratios = np.arange(0, 1.2, .2)\n",
    "max_iters = [1e4]\n",
    "nalphas = len(alphas)\n",
    "nl1_ratios = len(l1_ratios)\n",
    "\n",
    "param_grid = # TODO\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Perform the GridSearch using an ElasticNet model and the parameter grid \n",
    "constructed above. Use 10 cross validation folds, rmse_deg_scoring for \n",
    "the scoring function, any number of n_jobs to improve performance speed \n",
    "without causing memory leaks or time outs, return_train_score=True, iid=False, \n",
    "and set the verbosity to 1. Execute the grid search using the training data.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Get and display the best parameter set\n",
    "\n",
    "Note: see the best_params_ property of the GridSearchCV object\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Get and fit the best estimator to the training data\n",
    "\n",
    "Note: see the best_estimator_ property of the GridSearchCV object\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Get and display the first few lines of results from the gridsearch \n",
    "\n",
    "Note: see the cv_results_ property of GridSearchCV. And, remember that this dict\n",
    "can be converted to a DataFrame\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Extract and negate the mean_train_score\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Extract and negate the mean_test_score\n",
    "\n",
    "Note: although scikit-learn refers to this as a \"test score,\" it is actually\n",
    "a validation score.  Remember, you are not allowed to look at the test set\n",
    "performance across a grid of parameter choices (only look at the one test score \n",
    "for the hyper parameter set that you select).\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the Training and Testing rMSEs in degrees for the best estimator.\n",
    "You can use rmse_deg_scorer for this\n",
    "\"\"\"\n",
    "# Train rmse\n",
    "\n",
    "\n",
    "# Test rmse (note: this is the proper test set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Plot the test set predictions for the best model compared with\n",
    "the ground truth and the test set predictions from the linear model, \n",
    "for 1170 to 1187 seconds\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Plot the mean training and validation results from the grid search as a c\n",
    "olormap, for the alpha (y-axis) vs the l1 ratio (x-axis). Use two subplots, \n",
    "subplot(1,2,1) for the training set performance and subplot(1,2,2) for the \n",
    "validation set performance. You can use imshow or matshow to display colormaps. \n",
    "Make sure to include appropriate labels, ticks, and colorbars\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Generate a plot that contains two overlapping histograms:\n",
    "- Coefficients discovered by LinearRegression\n",
    "- Coefficients discovered by the best ElasticNet \n",
    "    (best is relative to the validation performnce)\n",
    "\"\"\"\n",
    "nbins = 21\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
